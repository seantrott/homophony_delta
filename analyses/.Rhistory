correct_total = mean(M))
```
Japanese already has frequency data, but we need to make sure it's summed across lemmas.
```{r}
df_japanese_lemmas = read_csv("../data/processed/japanese/reals/japanese_all_reals_4phone.csv")
nrow(df_japanese_lemmas)
df_japanese_lemmas = df_japanese_lemmas %>%
group_by(phonetic_remapped) %>%
summarise(total_frequency = sum(frequency))
nrow(df_japanese_lemmas)
df_japanese_merged = df_japanese %>%
inner_join(df_japanese_lemmas, by = "phonetic_remapped")
nrow(df_japanese)
nrow(df_japanese_merged)
df_japanese_merged$frequency = log10(df_japanese_merged$total_frequency + 1)
```
Now, visualize the relationship.
```{r}
df_japanese_merged %>%
plot_comparison()
df_japanese_merged %>%
plot_bins(n = 20, column = "frequency", label = "Binned frequency")
```
And finally, we can run the regression and visualize model coefficients:
```{r}
output = df_japanese_merged %>%
run_regression()
output %>%
plot_outcome()
output$model
output$comparison
```
Directly contrast the relationships:
```{r}
df_japanese_merged %>%
plot_contrast(bins = 20)
```
### Calculate Sense Entropy
```{r}
df_japanese_lemmas = read_csv("../data/processed/japanese/reals/japanese_all_reals_4phone.csv")
nrow(df_japanese_lemmas)
df_japanese_lemmas = df_japanese_lemmas %>%
mutate(freq_adjusted = frequency + 1) %>%
# mutate(freq_adjusted = log10(frequency + 1) + .01) %>%
group_by(phonetic_remapped) %>%
mutate(total_frequency = sum(freq_adjusted),
relative_frequency = freq_adjusted / total_frequency)
df_entropy = df_japanese_lemmas %>%
group_by(phonetic_remapped) %>%
summarise(entropy = -sum(relative_frequency * log(relative_frequency)))
df_japanese_entropy = df_japanese_merged %>%
inner_join(df_entropy, by = "phonetic_remapped")
nrow(df_japanese_entropy)
nrow(filter(df_japanese_entropy, num_homophones == 1))
model_full = lm(data = filter(df_japanese_entropy, num_homophones == 1),
delta ~ entropy + frequency + num_sylls_est + normalized_surprisal)
summary(model_full)
model_reduced = lm(data = filter(df_japanese_entropy, num_homophones ==1),
delta ~ frequency + num_sylls_est + normalized_surprisal)
anova(model_reduced, model_full)
```
## Mandarin: CallHome
```{r}
df_mandarin = read_data("../data/processed/mandarin/reals/mandarin_with_mps_4phone_holdout.csv")
nrow(df_mandarin)
## Now normalize probabilities and compute expected homophones per wordform
df_mandarin = df_mandarin %>%
normalize_probabilities() %>%
compute_expected_homophones()
nrow(df_mandarin)
## Double-check that this equals correct amount in lexicon
df_mandarin %>%
group_by(num_sylls_est) %>%
summarise(total = sum(k + 1),
correct_total = mean(M))
```
Mandarin already has frequency data, but we need to make sure it's summed across lemmas.
```{r}
df_mandarin_lemmas = read_csv("../data/processed/mandarin/reals/mandarin_all_reals_4phone.csv")
df_mandarin_lemmas = df_mandarin_lemmas %>%
mutate(frequency = FreqPM * 1000000) %>%
group_by(phonetic_remapped) %>%
summarise(total_frequency = sum(frequency))
nrow(df_mandarin_lemmas)
df_mandarin_merged = df_mandarin %>%
inner_join(df_mandarin_lemmas, by = "phonetic_remapped")
nrow(df_mandarin)
nrow(df_mandarin_merged)
df_mandarin_merged$frequency = log10(df_mandarin_merged$total_frequency + 1)
```
Now we can visualize the outcome in a variety of ways:
```{r}
df_mandarin_merged %>%
plot_comparison()
df_mandarin_merged %>%
plot_bins(n = 20, column = "frequency", label = "Binned frequency")
```
And finally, we can run the regression and visualize model coefficients:
```{r}
output = df_mandarin_merged %>%
run_regression()
output %>%
plot_outcome()
output$model
output$comparison
```
Directly contrast the relationships:
```{r}
df_mandarin_merged %>%
plot_contrast(bins = 20)
```
## Mandarin: Chinese Lexical Database
Here, we calculate the `Homophony Delta` for Mandarin Chinese, using the **Chinese Lexical Database**.
```{r}
df_mandarin_cld = read_data("../data/processed/mandarin_cld/reals/mandarin_cld_with_mps_4phone_holdout.csv")
nrow(df_mandarin_cld)
## Now normalize probabilities and compute expected homophones per wordform
df_mandarin_cld = df_mandarin_cld %>%
normalize_probabilities() %>%
compute_expected_homophones()
nrow(df_mandarin_cld)
## Double-check that this equals correct amount in lexicon
df_mandarin_cld %>%
group_by(num_sylls_est) %>%
summarise(total = sum(k + 1),
correct_total = mean(M))
```
Mandarin already has frequency data, but we need to make sure it's summed across lemmas.
```{r}
df_mandarin_lemmas = read_csv("../data/processed/mandarin_cld/reals/mandarin_cld_all_reals_4phone.csv")
nrow(df_mandarin_lemmas)
df_mandarin_lemmas = df_mandarin_lemmas %>%
group_by(phonetic_remapped) %>%
summarise(total_frequency = sum(FrequencyRaw))
nrow(df_mandarin_lemmas)
df_mandarin_merged = df_mandarin_cld %>%
inner_join(df_mandarin_lemmas, by = "phonetic_remapped")
nrow(df_mandarin)
nrow(df_mandarin_merged)
df_mandarin_merged$frequency = log10(df_mandarin_merged$total_frequency)
```
Now we can visualize the outcome in a variety of ways:
```{r}
df_mandarin_merged %>%
plot_comparison()
df_mandarin_merged %>%
plot_bins(n = 20, column = "frequency", label = "Binned frequency")
```
And finally, we can run the regression and visualize model coefficients:
```{r}
output = df_mandarin_merged %>%
run_regression()
output %>%
plot_outcome()
output$model
output$comparison
```
Directly contrast the relationships:
```{r}
df_mandarin_merged %>%
plot_contrast(bins = 20)
```
### Calculate Sense Entropy
```{r}
df_mandarin_lemmas = read_csv("../data/processed/mandarin_cld/reals/mandarin_cld_all_reals_4phone.csv")
nrow(df_mandarin_lemmas)
df_mandarin_lemmas = df_mandarin_lemmas %>%
mutate(freq_adjusted = FrequencyRaw + 1) %>%
# mutate(freq_adjusted = log10(frequency + 1) + .01) %>%
group_by(phonetic_remapped) %>%
mutate(total_frequency = sum(freq_adjusted),
relative_frequency = freq_adjusted / total_frequency)
df_entropy = df_mandarin_lemmas %>%
group_by(phonetic_remapped) %>%
summarise(entropy = -sum(relative_frequency * log(relative_frequency)))
df_mandarin_entropy = df_mandarin_merged %>%
inner_join(df_entropy, by = "phonetic_remapped")
nrow(df_mandarin_entropy)
nrow(filter(df_mandarin_entropy, num_homophones == 1))
model_full = lm(data = filter(df_mandarin_entropy, num_homophones == 1),
delta ~ entropy + frequency + num_sylls_est + normalized_surprisal)
summary(model_full)
model_reduced = lm(data = filter(df_mandarin_entropy, num_homophones ==1),
delta ~ frequency + num_sylls_est + normalized_surprisal)
anova(model_reduced, model_full)
df_merged_english_f = df_merged_english %>%
mutate(binned_frequency = ntile(frequency, n = 20)) %>%
mutate(binned_neighorhood_size = ntile(neighborhood_size, n = 20)) %>%
mutate(language = 'English') %>%
select(num_sylls_est, normalized_surprisal, binned_neighorhood_size,
num_homophones, k, frequency, binned_frequency, delta, language)
df_merged_dutch_f = df_merged_dutch %>%
mutate(binned_frequency = ntile(frequency, n = 20)) %>%
mutate(binned_neighorhood_size = ntile(neighborhood_size, n = 20)) %>%
mutate(language = 'Dutch') %>%
select(num_sylls_est, normalized_surprisal, binned_neighorhood_size,
num_homophones, k, frequency, binned_frequency, delta, language)
df_merged_german_f = df_merged_german %>%
mutate(binned_frequency = ntile(frequency, n = 20)) %>%
mutate(binned_neighorhood_size = ntile(neighborhood_size, n = 20)) %>%
mutate(language = 'German') %>%
select(num_sylls_est, normalized_surprisal, binned_neighorhood_size,
num_homophones, k, frequency, binned_frequency, delta, language)
df_french_f = df_french %>%
mutate(binned_frequency = ntile(frequency, n = 20)) %>%
mutate(binned_neighorhood_size = ntile(neighborhood_size, n = 20)) %>%
mutate(language = 'French') %>%
select(num_sylls_est, normalized_surprisal, binned_neighorhood_size,
num_homophones, k, frequency, binned_frequency, delta, language)
df_japanese_f = df_japanese_merged %>%
mutate(binned_frequency = ntile(frequency, n = 20)) %>%
mutate(binned_neighorhood_size = ntile(neighborhood_size, n = 20)) %>%
mutate(language = 'Japanese') %>%
select(num_sylls_est, normalized_surprisal, binned_neighorhood_size,
num_homophones, k, frequency, binned_frequency, delta, language)
df_mandarin_cld_f = df_mandarin_merged %>%
mutate(binned_frequency = ntile(frequency, n = 20)) %>%
mutate(binned_neighorhood_size = ntile(neighborhood_size, n = 20)) %>%
mutate(language = 'Mandarin') %>%
select(num_sylls_est, normalized_surprisal, binned_neighorhood_size,
num_homophones, k, frequency, binned_frequency, delta, language)
df_all_lexica = df_merged_english_f %>%
rbind(df_merged_dutch_f) %>%
rbind(df_merged_german_f) %>%
rbind(df_french_f) %>%
rbind(df_japanese_f) %>%
rbind(df_mandarin_cld_f)
PlotTheme = theme(
axis.title.x = element_text(size = 16),
axis.text.x = element_text(size = 14),
axis.text.y = element_text(size = 14),
axis.title.y = element_text(size = 16),
strip.text.x = element_text(size = 16),
title = element_text(size = 16),
legend.text = element_text(size = 16),
legend.title = element_text(size = 16))
df_all_lexica %>%
mutate(expected = k,
actual = num_homophones) %>%
pivot_longer(c(expected, actual),
names_to = "model",
values_to = "homophones") %>%
group_by(binned_neighorhood_size, language, model) %>%
summarise(mean_homophones = mean(homophones),
se_homophones = sd(homophones) / sqrt(n())) %>%
ggplot(aes(x = binned_neighorhood_size,
y = mean_homophones,
color = model)) +
geom_point(stat = "identity", size = .5, alpha = .5) +
geom_hline(yintercept = 0, linetype = "dotted") +
geom_errorbar(aes(ymin = mean_homophones - 2 * se_homophones,
ymax = mean_homophones + 2 * se_homophones),
width=.2) +
labs(x = "Binned Neighborhood Size",
y = "Number of Homophones") +
geom_smooth(alpha = .6) +
theme_bw() +
facet_wrap(~language) +
PlotTheme
PlotTheme = theme(
axis.title.x = element_text(size = 16),
axis.text.x = element_text(size = 12),
axis.text.y = element_text(size = 14),
axis.title.y = element_text(size = 16),
strip.text.x = element_text(size = 16),
title = element_text(size = 16),
legend.text = element_text(size = 16),
legend.title = element_text(size = 16))
df_all_lexica %>%
mutate(expected = k,
actual = num_homophones) %>%
pivot_longer(c(expected, actual),
names_to = "model",
values_to = "homophones") %>%
group_by(binned_neighorhood_size, language, model) %>%
summarise(mean_homophones = mean(homophones),
se_homophones = sd(homophones) / sqrt(n())) %>%
ggplot(aes(x = binned_neighorhood_size,
y = mean_homophones,
color = model)) +
geom_point(stat = "identity", size = .5, alpha = .5) +
geom_hline(yintercept = 0, linetype = "dotted") +
geom_errorbar(aes(ymin = mean_homophones - 2 * se_homophones,
ymax = mean_homophones + 2 * se_homophones),
width=.2) +
labs(x = "Binned Neighborhood Size",
y = "Number of Homophones") +
geom_smooth(alpha = .6) +
theme_bw() +
facet_wrap(~language) +
PlotTheme
df_all_lexica %>%
mutate(expected = k,
actual = num_homophones) %>%
pivot_longer(c(expected, actual),
names_to = "model",
values_to = "homophones") %>%
group_by(binned_neighorhood_size, language, model) %>%
summarise(mean_homophones = mean(homophones),
se_homophones = sd(homophones) / sqrt(n())) %>%
ggplot(aes(x = binned_neighorhood_size,
y = mean_homophones,
color = model)) +
geom_point(stat = "identity", size = .5, alpha = .5) +
geom_hline(yintercept = 0, linetype = "dotted") +
geom_errorbar(aes(ymin = mean_homophones - 2 * se_homophones,
ymax = mean_homophones + 2 * se_homophones),
width=.2) +
labs(x = "Binned Neighborhood Size",
y = "Number of Homophones") +
geom_smooth(alpha = .6) +
theme_bw() +
facet_wrap(~language) +
PlotTheme +
theme(panel.spacing = unit(2, "lines"))
df_all_lexica %>%
mutate(expected = k,
actual = num_homophones) %>%
pivot_longer(c(expected, actual),
names_to = "model",
values_to = "homophones") %>%
group_by(binned_neighorhood_size, language, model) %>%
summarise(mean_homophones = mean(homophones),
se_homophones = sd(homophones) / sqrt(n())) %>%
ggplot(aes(x = binned_neighorhood_size,
y = mean_homophones,
color = model)) +
geom_point(stat = "identity", size = .5, alpha = .5) +
geom_hline(yintercept = 0, linetype = "dotted") +
geom_errorbar(aes(ymin = mean_homophones - 2 * se_homophones,
ymax = mean_homophones + 2 * se_homophones),
width=.2) +
labs(x = "Binned Neighborhood Size",
y = "Number of Homophones") +
geom_smooth(alpha = .6) +
theme_bw() +
facet_wrap(~language) +
PlotTheme +
theme(panel.spacing.x = unit(1, "lines"))
PlotTheme = theme(
axis.title.x = element_text(size = 16),
axis.text.x = element_text(size = 14),
axis.text.y = element_text(size = 14),
axis.title.y = element_text(size = 16),
strip.text.x = element_text(size = 16),
title = element_text(size = 16),
legend.text = element_text(size = 16),
legend.title = element_text(size = 16))
df_all_lexica %>%
mutate(expected = k,
actual = num_homophones) %>%
pivot_longer(c(expected, actual),
names_to = "model",
values_to = "homophones") %>%
group_by(binned_neighorhood_size, language, model) %>%
summarise(mean_homophones = mean(homophones),
se_homophones = sd(homophones) / sqrt(n())) %>%
ggplot(aes(x = binned_neighorhood_size,
y = mean_homophones,
color = model)) +
geom_point(stat = "identity", size = .5, alpha = .5) +
geom_hline(yintercept = 0, linetype = "dotted") +
geom_errorbar(aes(ymin = mean_homophones - 2 * se_homophones,
ymax = mean_homophones + 2 * se_homophones),
width=.2) +
labs(x = "Binned Neighborhood Size",
y = "Number of Homophones") +
geom_smooth(alpha = .6) +
theme_bw() +
facet_wrap(~language) +
PlotTheme +
theme(panel.spacing.x = unit(1.5, "lines"))
ggsave("../Figures/direct_comparison_neighbors.png", dpi = 300)
df_all_lexica %>%
group_by(binned_frequency, language) %>%
summarise(mean_delta = mean(delta),
se_delta = sd(delta) / sqrt(n())) %>%
ggplot(aes(x = binned_frequency,
y = mean_delta)) +
geom_point(stat = "identity", size = .2) +
geom_hline(yintercept = 0, linetype = "dotted") +
geom_errorbar(aes(ymin = mean_delta - 2 * se_delta,
ymax = mean_delta + 2 *se_delta),
width=.2,
position=position_dodge(.9)) +
labs(x = "Binned Frequency",
y = "Delta (Real - Expected)") +
geom_smooth() +
theme_bw() +
facet_wrap(~language) +
PlotTheme
df_all_lexica %>%
mutate(expected = k,
actual = num_homophones) %>%
pivot_longer(c(expected, actual),
names_to = "model",
values_to = "homophones") %>%
group_by(binned_frequency, language, model) %>%
summarise(mean_homophones = mean(homophones),
se_homophones = sd(homophones) / sqrt(n())) %>%
ggplot(aes(x = binned_frequency,
y = mean_homophones,
color = model)) +
geom_point(stat = "identity", size = .5, alpha = .5) +
geom_hline(yintercept = 0, linetype = "dotted") +
geom_errorbar(aes(ymin = mean_homophones - 2 * se_homophones,
ymax = mean_homophones + 2 * se_homophones),
width=.2) +
labs(x = "Binned Frequency",
y = "Number of Homophones") +
geom_smooth(alpha = .6) +
theme_bw() +
facet_wrap(~language) +
PlotTheme
df_all_lexica %>%
mutate(expected = k,
actual = num_homophones) %>%
pivot_longer(c(expected, actual),
names_to = "model",
values_to = "homophones") %>%
group_by(binned_frequency, language, model) %>%
summarise(mean_homophones = mean(homophones),
se_homophones = sd(homophones) / sqrt(n())) %>%
ggplot(aes(x = binned_frequency,
y = mean_homophones,
color = model)) +
geom_point(stat = "identity", size = .5, alpha = .5) +
geom_hline(yintercept = 0, linetype = "dotted") +
geom_errorbar(aes(ymin = mean_homophones - 2 * se_homophones,
ymax = mean_homophones + 2 * se_homophones),
width=.2) +
labs(x = "Binned Frequency",
y = "Number of Homophones") +
geom_smooth(alpha = .6) +
theme_bw() +
facet_wrap(~language) +
PlotTheme +
theme(panel.spacing.x = unit(1.5, "lines"))
ggsave("../Figures/direct_comparison_frequency.png", dpi = 300)
predict_neighborhood_size = function(df) {
# initialize output
out = list()
# Log neighborhood
df$log_neighborhood = log10(df$neighborhood_size + 1)
# Build full model
model_full = lm(data = df,
log_neighborhood ~ frequency + num_sylls_est + normalized_surprisal + delta)
# Build reduced model
model_reduced = lm(data = df,
log_neighborhood ~ num_sylls_est + normalized_surprisal + frequency)
# Run model comparison
comparison = anova(model_reduced, model_full)
df_comp = broom::tidy(comparison) %>%
na.omit()
# Tidy model output
df_model = broom::tidy(model_full)
# Add to list parameters
out$model = df_model
out$comparison = df_comp
out
}
df_merged_english %>%
plot_bins(n = 20, column = "neighborhood_size", label = "Binned neighborhood_size")
output = df_merged_english %>%
predict_neighborhood_size()
output$model
output$comparison
exp(-0.00147)
exp(.00147)
predict_neighborhood_size = function(df) {
# initialize output
out = list()
# Log neighborhood
df$log_neighborhood = log10(df$neighborhood_size + 1)
# Build full model
model_full = lm(data = df,
neighborhood_size ~ frequency + num_sylls_est + normalized_surprisal + delta)
# Build reduced model
model_reduced = lm(data = df,
neighborhood_size ~ num_sylls_est + normalized_surprisal + frequency)
# Run model comparison
comparison = anova(model_reduced, model_full)
df_comp = broom::tidy(comparison) %>%
na.omit()
# Tidy model output
df_model = broom::tidy(model_full)
# Add to list parameters
out$model = df_model
out$comparison = df_comp
out
}
df_merged_english %>%
plot_bins(n = 20, column = "neighborhood_size", label = "Binned neighborhood_size")
output = df_merged_english %>%
predict_neighborhood_size()
output$model
output = df_merged_german %>%
predict_neighborhood_size()
output$model
output$comparison
output = df_french %>%
predict_neighborhood_size()
output$model
output$comparison
output = df_japanese_merged %>%
predict_neighborhood_size()
output$model
output$comparison
output = df_mandarin_merged %>%
predict_neighborhood_size()
output$model
output$comparison
